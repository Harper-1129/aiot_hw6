{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3rZfw5ux-Lm",
        "outputId": "ca822219-7c4e-495b-9699-eff9325ca0ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Face-Mask-Detection'...\n",
            "remote: Enumerating objects: 4590, done.\u001b[K\n",
            "remote: Total 4590 (delta 0), reused 0 (delta 0), pack-reused 4590 (from 1)\u001b[K\n",
            "Receiving objects: 100% (4590/4590), 186.72 MiB | 19.43 MiB/s, done.\n",
            "Resolving deltas: 100% (271/271), done.\n",
            "Updating files: 100% (4155/4155), done.\n",
            "Contents of cloned repository: ['README - Korean.md', '__pycache__', 'Logo', 'detect_mask_video.py', '.DS_Store', 'mask_detector.model', 'requirements.txt', 'face_detector', 'css', 'CODE_OF_CONDUCT.md', 'CONTRIBUTING.md', 'app.py', 'images', 'plot.png', 'CITATION.cff', 'LICENSE', 'Windows_guide.md', 'README.md', 'ResNet50_v2', 'detect_mask_image.py', 'model2onnx.py', 'search.py', 'train_mask_detector.py', 'incep_v3_mask_model', '.github', '_config.yml', '.gitignore', '.git', 'Readme_images', 'dataset']\n",
            "Contents of dataset folder: ['with_mask', 'without_mask']\n",
            "Found 3274 images belonging to 2 classes.\n",
            "Found 818 images belonging to 2 classes.\n",
            "Epoch 1/5\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2681s\u001b[0m 26s/step - accuracy: 0.8168 - loss: 0.6454 - val_accuracy: 0.9866 - val_loss: 0.0793\n",
            "Epoch 2/5\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2676s\u001b[0m 26s/step - accuracy: 0.9487 - loss: 0.1342 - val_accuracy: 0.9609 - val_loss: 0.1089\n",
            "Epoch 3/5\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2657s\u001b[0m 26s/step - accuracy: 0.9641 - loss: 0.1014 - val_accuracy: 0.9804 - val_loss: 0.0536\n",
            "Epoch 4/5\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2659s\u001b[0m 26s/step - accuracy: 0.9749 - loss: 0.0752 - val_accuracy: 0.9743 - val_loss: 0.0704\n",
            "Epoch 5/5\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2618s\u001b[0m 25s/step - accuracy: 0.9593 - loss: 0.1015 - val_accuracy: 0.9841 - val_loss: 0.0465\n",
            "Enter image URL: https://na.cx/i/eqzQJYw.jpg\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 829ms/step\n",
            "Predicted Class: with_mask\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import os\n",
        "\n",
        "# Clone dataset repository\n",
        "!git clone https://github.com/chandrikadeb7/Face-Mask-Detection.git\n",
        "\n",
        "# Change working directory to the cloned repository\n",
        "# This ensures the relative paths are correct\n",
        "os.chdir(\"Face-Mask-Detection\")\n",
        "\n",
        "# Verify dataset structure\n",
        "print(\"Contents of cloned repository:\", os.listdir(\".\"))\n",
        "\n",
        "data_dir = \"dataset\"\n",
        "if not os.path.exists(data_dir):\n",
        "    raise FileNotFoundError(\"Dataset folder not found. Verify the dataset structure.\")\n",
        "\n",
        "# List dataset contents\n",
        "print(\"Contents of dataset folder:\", os.listdir(data_dir))\n",
        "\n",
        "# Define image parameters\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Image preprocessing\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2,\n",
        "                                   rotation_range=30, shear_range=0.2,\n",
        "                                   zoom_range=0.2, horizontal_flip=True)\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    data_dir, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='binary', subset='training')\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    data_dir, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='binary', subset='validation')\n",
        "\n",
        "# Load pre-trained VGG16 model\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze base model layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Build new classifier on top\n",
        "x = Flatten()(base_model.output)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(train_generator, validation_data=val_generator, epochs=5)\n",
        "\n",
        "# Function to classify image from URL\n",
        "def test_image(image_url, model, class_names):\n",
        "    response = requests.get(image_url)\n",
        "    img = Image.open(BytesIO(response.content)).resize((224, 224))\n",
        "    img_array = np.array(img) / 255.0\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    prediction = model.predict(img_array)[0][0]\n",
        "    predicted_class = class_names[0] if prediction < 0.5 else class_names[1]\n",
        "    print(f\"Predicted Class: {predicted_class}\")\n",
        "\n",
        "# Example usage\n",
        "image_url = input(\"Enter image URL: \")\n",
        "test_image(image_url, model, list(train_generator.class_indices.keys()))\n"
      ]
    }
  ]
}